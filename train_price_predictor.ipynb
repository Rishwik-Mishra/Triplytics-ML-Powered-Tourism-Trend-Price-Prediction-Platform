{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4631ea9-9acd-47b5-8983-e63fcfcf8fc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "print(\"Libraries imported successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "219fe0fb-4af4-4984-aad4-ab34233cb3bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded 'passenger_train_data_expanded.csv'. Found 180839 rows.\n",
      "Feature engineering complete.\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Load Data and Engineer Features ---\n",
    "# --- THIS IS THE CHANGE: Using your new expanded file ---\n",
    "input_filename = 'passenger_train_data_expanded.csv'\n",
    "\n",
    "try:\n",
    "    df_train = pd.read_csv(input_filename, sep=',')\n",
    "    print(f\"Successfully loaded '{input_filename}'. Found {len(df_train)} rows.\")\n",
    "\n",
    "    # --- 2. Engineer Features ---\n",
    "    df_train['timeStamp'] = pd.to_datetime(df_train['timeStamp'])\n",
    "    df_train['booking_month'] = df_train['timeStamp'].dt.month\n",
    "    df_train['booking_day_of_week'] = df_train['timeStamp'].dt.dayofweek\n",
    "    df_train['booking_hour'] = df_train['timeStamp'].dt.hour\n",
    "    \n",
    "    print(\"Feature engineering complete.\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: '{input_filename}' not found.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df9c5523-a2f9-4666-b94d-952a2ef22664",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows after dropping any missing values: 180839\n",
      "--- 'Passenger' Feature Set (X) ---\n",
      "  fromStnCode toStnCode classCode  distance  duration  booking_month  \\\n",
      "0         JBP      SRID        1A        54      33.0             10   \n",
      "1         JBP      SRID        2A        54      33.0             10   \n",
      "2         JBP      SRID        3A        54      33.0             10   \n",
      "3         JBP      SRID        SL        54      33.0             10   \n",
      "4         JBP       KKB        1A        69      49.0             10   \n",
      "\n",
      "   booking_day_of_week  booking_hour  \n",
      "0                    1            22  \n",
      "1                    1            22  \n",
      "2                    1            22  \n",
      "3                    1            22  \n",
      "4                    1            22  \n",
      "Data split into 126587 training rows and 54252 test rows.\n"
     ]
    }
   ],
   "source": [
    "# --- 3. Define Feature Set (X) and Target (y) ---\n",
    "feature_cols = [\n",
    "    'fromStnCode', \n",
    "    'toStnCode', \n",
    "    'classCode', \n",
    "    'distance', \n",
    "    'duration', \n",
    "    'booking_month', \n",
    "    'booking_day_of_week',\n",
    "    'booking_hour'\n",
    "]\n",
    "\n",
    "df_train = df_train.dropna(subset=['totalFare'] + feature_cols)\n",
    "print(f\"Rows after dropping any missing values: {len(df_train)}\")\n",
    "\n",
    "X = df_train[feature_cols]\n",
    "y = df_train['totalFare']\n",
    "\n",
    "print(\"--- 'Passenger' Feature Set (X) ---\")\n",
    "print(X.head())\n",
    "\n",
    "# --- 4. Define Preprocessing ---\n",
    "categorical_features = ['fromStnCode', 'toStnCode', 'classCode']\n",
    "numerical_features = ['distance', 'duration', 'booking_month', \n",
    "                      'booking_day_of_week', 'booking_hour']\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_features),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "    ])\n",
    "\n",
    "# --- 5. Split the Data ---\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=37)\n",
    "\n",
    "print(f\"Data split into {len(X_train)} training rows and {len(X_test)} test rows.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a5127c6-cb5d-4ab0-9476-7cac2b3bce71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the RandomForest model on 180,839 rows...\n",
      "Training complete.\n"
     ]
    }
   ],
   "source": [
    "# --- 6. Create and Train the Pipeline ---\n",
    "rf_model = RandomForestRegressor(n_estimators=100, n_jobs=-1, random_state=42)\n",
    "\n",
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                           ('model', rf_model)])\n",
    "\n",
    "# --- NOTE ---\n",
    "# This will take longer to train than before, as the dataset is\n",
    "# now much larger (180k rows vs 52k). Please be patient.\n",
    "print(\"Training the RandomForest model on 180,839 rows...\")\n",
    "pipeline.fit(X_train, y_train)\n",
    "print(\"Training complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8734f31-8994-49ee-a6dd-ab101383f7fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 'Passenger' Model Performance (Expanded Dataset) ---\n",
      "R-squared (R²): 0.9879\n",
      "Mean Absolute Error (MAE): 38.50\n"
     ]
    }
   ],
   "source": [
    "# --- 7. Evaluate the New Model ---\n",
    "y_pred = pipeline.predict(X_test)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "print(f\"\\n--- 'Passenger' Model Performance (Expanded Dataset) ---\")\n",
    "print(f\"R-squared (R²): {r2:.4f}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2275bc0c-d61d-44c8-b885-67f4ca50b5e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New, expanded train pipeline saved as 'train_price_pipeline.pkl'\n"
     ]
    }
   ],
   "source": [
    "# --- 8. Save the New Model ---\n",
    "# We save it with the SAME name. This will overwrite the old,\n",
    "# smaller model, and the app will automatically use this new one.\n",
    "output_model_name = 'train_price_pipeline.pkl'\n",
    "joblib.dump(pipeline, output_model_name)\n",
    "print(f\"\\nNew, expanded train pipeline saved as '{output_model_name}'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
